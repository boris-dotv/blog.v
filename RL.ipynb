{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "强化学习的几个组成部分:  \n",
    "* **Agent**, agents learn to take actions to maximize expected reward.\n",
    "* **Action**, change the environment.\n",
    "* **Environment**, the place where agents are expected to maximize expected reward.\n",
    "* **Reward**, a feedback from pre-defined rule or reward model.\n",
    "* **Observation**, agents 对当前环境 state 的观察, 注意 state 不总是等于 observation, 比如在象棋游戏中, 当前棋盘的 state 就是 agents 的 observation, 在扑克牌中, 当前棋盘的 state 就是打出的牌和所有 agents 手里的牌, 但 observation 是 agents 手里的牌. state 是\"上帝视角\", observation 是 agent 视角.\n",
    "\n",
    "### Policy-based Approach (Learning an Actor)\n",
    "Machine learning 的终极目标可以大致描述为 Looking for a function. 在 RL 中, Observation, Actor/Policy, Action 的关系可以表示为:  \n",
    "\n",
    "$$Action = \\pi(Observation)$$\n",
    "\n",
    "我们定义 $\\bar{R}_{\\theta}$ 作为 $R_{\\theta}$ 的期望值."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
